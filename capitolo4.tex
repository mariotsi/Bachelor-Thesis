%!TEX root = Tesi__Simone_Mariotti.tex
\chapter{Implementazione}
\fancyhead[R]{\bfseries Implementazione} 	
\fancyfoot[C]{\thepage }
È definito ``agente'' una qualunque entità in grado di percepire l'ambiente
circostante attraverso dei sensori e di eseguire delle azioni attraverso degli
attuatori. Nel campo dell'intelligenza artificiale è definito intelligente quel-
l'agente che fa la cosa giusta al momento giusto. Il compito dell'agente è
quello di stabilire una sequenza di azioni che portano al raggiungimento di
uno stato obiettivo.\cite{agente}

Il successivo diagramma descrive in linea di massima, il funzionamento dell'algoritmo che governa l'agente: preso un frame e un messaggio
di Arduino restituisce una risposta generata dalla logica dell'app.
\begin{figure}[H] \center
\includegraphics[width=\textwidth]{immagini/schema_processo_new.pdf}
\caption{Processo decisionale del sistema} 
\end{figure}
Le fasi principali sono:
\begin{enumerate}
\item ricezione del messaggio da Arduino.
\item salvataggio e decodifica del messaggio.
\item lettura del messaggio da parte del modulo di IA.
\item acquisizione dell'obiettivo dall'ambiente.
\item preparazione del comando elaborato dall'IA.
\item invio del comando ad Arduino.
\end{enumerate}

\section {Android}
L'app per Android è stata sviluppata avendo come priorità la modularità. 
Difatti è previsto un meccanismo per alterare il comportamento dell'agente, 
sostituendo o modificando una singola classe senza coinvolgere il resto del codice.\\
La modularizzazione a grana grossa viene fatta a livello di pacchetto\footnote{Un contenitore 
che racchiude classi che svolgono compitini affini.}. Ci sono tre pacchetti,
ognuno con un compito preciso, \textbf{logic}, \textbf{messaging} e \textbf{opencv}.
\begin{figure}[H] \center
\includegraphics[width=\textwidth]{immagini/interconnessione_pacchetti.pdf}
\caption{Schema di interconnessione dei pacchetti} 
\end{figure}

\subsection {Il pacchetto \textit{opencv}}
Il pacchetto \textbf{opencv} si occupa di analizzare 
i frame proveniente dalla camera alla ricerca dell'obiettivo, comunicando poi la posizione 
dell'obiettivo o l'assenza dello stesso alla classe RobotLogic del pacchetto 
\textbf{logic}.

\subsubsection{La classe \emph{ColorBlobDetector}}
ColorBlobDetector è la classe che effettivamente cerca l'obiettivo nei
frame proveniente dalla camera. L'obiettivo gli viene fornito da RobotActivity 
tramite \emph{setTargetHsvColor()} nel momento in cui l'utente lo indica 
sull'interfaccia utente. I colori in OpenCV vengono rappresentati con un tipo di dato interno
detto Scalar che si comporta in modo simile ad un array. Il metodo che esegue 
l'operazione di ricerca è \emph{process()}. Per prima cosa converte lo schema di 
colori del frame sotto analisi da RGBa\footnote{Ogni colore è rappresentato da 
quattro canali: R (red), G (green), B (blue) e a (alpha).} a HSV\footnote{Anche in questo
schema i colori sono rappresentati da quattro canali ma hanno denominazione e 
significato differenti: H (hue), S (saturation), V (value) e  a (alpha).} e filtra l'immagine in modo che rimangano solo 
i pixel che hanno un colore che si trova entro un certo intorno del colore cercato.
Viene poi chiamata la funzione fornita da OpenCV \emph{findContours()} che cerca i contorni delle
zone con il colore di nostro interesse e li restituisce come una un ArrayList di MatOfPoint;
MatOfPoint è un tipo di dato di OpenCV che è usato per memorizzare una quantità variabile
di punti che sono in relazione tra di loro, come quelli che delineano un contorno.
In seguito cerca il contorno che ha area maggiore e scarta tutti quelli che sono più piccoli 
del limite impostato ad un un'ordine di grandezza in meno. I contorni rimasti 
saranno quelli analizzati da TargetSearch. La scelta del limite è 
seguita a delle prove empiriche che hanno mostrato come questa soglia permetta di
scartare la quasi totalità di falsi positivi dovuti a riflessi o errori di 
rilevamento del colore. 

\subsubsection{La classe \emph{TargetSearch}}
Questa classe per prima cosa invoca \emph{process()} di ColorBlobDetector passandogli
il frame da analizzare e raccoglie i risultati tramite \emph{getContours()} che restituisce 
i contorni individuati da \emph{process()}.\\
Scorre poi uno ad uno i contorni così ricevuti e trova per ognuno un \emph{bounding rectangle}, 
cioè il rettangolo di area minima che contiene per intero il contorno corrente, 
scartando tutti i rettangoli minori di un certo valore e mantenendo un riferimento 
a quello di area maggiore trovato fino a quel momento. I rettangoli saranno tutti colorati di blu
tranne quello di area maggiore che sarà colorato di rosso. Sarà proprio questo 
rettangolo il nostro obiettivo.\\
Fornisce un feedback all'utente sul colore scelto e la gamma di colori simili 
che sono stati cercati.\\
Solo tre dati forniti da questa classe servono alla RobotLogic per valutare l'azione 
da intraprendere e sono:
la posizione dell'obiettivo, la larghezza del frame e il bounding rectangle 
che racchiude l'obiettivo.\\
Le posizioni sono sempre riferite all'asse x in quanto l'agente non 
ha capacità di movimento sull'asse y e possono essere:
\begin{itemize}
	\item TARGET\_POSITION\_LEFT: il centro dell'obiettivo si trova a sinistra del centro del frame. 
	\item TARGET\_POSITION\_RIGHT: il centro dell'obiettivo si trova a destra del centro del frame. 
	\item TARGET\_POSITION\_FRONT: il centro dell'obiettivo e il centro del frame coincidono. 
	\item TARGET\_POSITION\_NONE: l'obiettivo non è visibile.
\end{itemize}
In base alla posizione dell'obiettivo chiama il metodo adatto della classe UpdateDirection del pacchetto \textbf{logic}
per mostrare, sul display, l'azione che sta per eseguire l'agente.

\subsection{Il pacchetto \textit{messaging}}
Questo pacchetto è un modulo completamente a se stante, è così possibile cambiare il
protocollo di comunicazione senza alterare la logica dell'agente; al suo interno 
avviene la codifica e la decodifica di tutte le stringhe inerenti i messaggi ricevuti e 
inviati.
\\Nel nostro caso i messaggi sono formati da tre byte separati da virgole. I tre 
valori potranno quindi assumere 255 valori diversi.
I messaggi diretti da Arduino ad Android hanno questa forma:
\begin{center}
\textbf{MessageType,Message,Data}
\end{center}
dove MessageType può assumere due valori: INFO, indica che il messaggio trasporta un
dato informativo, o STATE, indica che il messaggio comunica lo stato in cui si trova Arduino.
\\Se il MessageType è INFO allora il Message può essere di due tipi: 
\begin{itemize}\item DISTANCE: sulla porzione Data del messaggio sarà presente 
la distanza del primo oggetto di fronte all'agente.
\item TERMINATE: indica l'intenzione di Arduino di chiudere l'app Android.
\end{itemize}
Se il MessageType è STATE allora il Message può essere di quattro tipi: 
\begin{itemize}
	\item IDLE: l'agente non sta eseguendo alcuna azione.
	\item SEARCHING: l'agente si sta muovendo in cerca dell'obiettivo.
	\item HUNTING: l'agente si sta muovendo verso l'obiettivo.
	\item EMERGENCY: l'agente è in emergenza, non eseguirà nessun comando fino al 
	termine della situazione di emergenza. 
\end{itemize}
I messaggi diretti da Android ad Arduino hanno invece questa forma:
\begin{center}
\textbf{Command,Parameter1,Parameter2}
\end{center}
Command identifica l'azione da eseguire, Parameter1 e Parameter2 sono due parametri opzionali
che modificano il comportamento standard dell'azione richiesta.

\subsubsection{La classe \emph{IncomingMessage}}
Questa classe è un ``singleton''\footnote{È un design pattern descritto dalla 
cosiddetta ``Gang of four'' nel libro ``Design Patterns''. 
Permette la creazione di una sola istanza della classe e ne regola l'accesso.} 
estende la classe Observable e insieme alla classe RobotLogic del 
pacchetto \textbf{logic} implementa il design pattern ``Observer-Observable''. 
\\Accoglie il messaggio ricevuto da Arduino, crea un oggetto di tipo ArduinoMessage 
per decodificare e custodire il messaggio ricevuto e informa gli Observer della presenza 
di un nuovo messaggio tramite \emph{triggerObservers()}.\\
Su richiesta fornisce l'ultimo messaggio ricevuto tramite \emph{getIncoming()}.

\subsubsection{La classe \emph{ArduinoMessage}}
In questa classe sono definite tutte le costanti necessarie per la 
decodifica delle stringhe ricevute da Arduino. 
Decodifica la stringa passatagli come parametro in fase di istanziazione ed 
espone diversi metodi che consentono di fare un controllo veloce sul contenuto del messaggio.
Un esempio della versatilità di questi metodi pubblici è:  
\lstset{language=Java}

\begin{lstlisting}[caption=Metodo \emph{update()} di RobotLogic del 
pacchetto \textbf{logic}]
@Override
public void update(Observable observable, Object data) {
    ArduinoMessage incomingMessage = IncomingMessage.getInstance().getIncoming();
    if (!incomingMessage.hasError()) {
        if (incomingMessage.isInfoMessage() && incomingMessage.hasDistance()) {
            mDistance = incomingMessage.getData();
        }
        if (incomingMessage.isTerminateCommand()) {
            mRobotActivity.finish();    }
}
\end{lstlisting}

\subsubsection{La classe \emph{MessageEncoder}}
In questa classe sono definite tutte le costanti necessarie per la codifica delle
stringhe da inviare Arduino ed espone numerosi metodi statici per la codifica vera e propria:
\begin{itemize}
    \item \emph{moveForward(int motorLeft, int motorRight)}: comanda di 
    muoversi in avanti e applicare ai motori le potenze indicate da motorLeft e motorRight
    \item \emph{moveForward()}: comanda di muoversi in avanti e applicare ai motori 
    potenza pari a DEFAULT\_VELOCITY ad entrambi i motori. 
    \item \emph{moveBackward(int motorLeft, int motorRight)}: comanda di 
    muoversi in indietro e applicare ai motori le potenze indicate da motorLeft e motorRight
    \item \emph{moveBackward()}: comanda di muoversi in indietro e applicare ai motori 
    potenza pari a DEFAULT\_VELOCITY ad entrambi i motori. 
    \item \emph{stop()}: comanda di fermarsi.
    \item \emph{turnLeft(int velocity, int mode)}: comanda di ruotare verso 
    sinistra e applicare ai motori potenza pari a \emph{velocity}.
    \item \emph{turnLeft(int mode)}: comanda di ruotare verso 
    sinistra e applicare ai motori potenza pari a DEFAULT\_VELOCITY.   
    \item \emph{turnRight(int velocity, int mode)}: comanda di ruotare verso 
    destra e applicare ai motori potenza pari a \emph{velocity}.
    \item \emph{turnRight(int mode)}: comanda di ruotare verso 
    destra e applicare ai motori potenza pari a DEFAULT\_VELOCITY.  
    \item \emph{search()}: comanda di cercare l'obiettivo.
\end{itemize}
Nei metodi \emph{turnLeft} e \emph{turnRight}, \emph{mode} può assumere il valore 
TURN\_ON\_SPOT o TURN\_NORMALLY che fanno girare l'agente rispettivamente utilizzando 
entrambi i cingoli o solo il cingolo opposto alla direzione di rotazione.\\
Grazie a questi metodi pubblici la parte di logica dell'app invia messaggi ad Arduino
senza avere la minima idea della stringa che effettivamente sarà inviata.\\
Tutto quello che si limita a fare per comandare, per esempio, ad Arduino di girare 
sul posto verso destro e con una velocità di 200 è:
\begin{lstlisting}[caption=Esempio di codifica e invio di un comando ad Arduino]
Communicator.setOutgoing(MessageEncoder.turnRight(200, MessageEncoderDecoder.TURN_ON_SPOT));
\end{lstlisting}

\subsubsection{La classe \emph{Communicator}}
Questa classe utilizza degli ``short-lived thread''\footnote{Threads che, una volta 
lanciati, terminano rapidamente.} per implementare la comunicazione da e verso Arduino.\\
Il thread lanciato ad intervalli regolati è definito da CommunicatorThread, che implementa l'interfaccia 
Runnable e definisce il metodo \emph{run()}; nel metodo \emph{run()} avviene
la vera e propria comunicazione con Arduino. Ad ogni esecuzione di \emph{run()} 
invia un messaggio ad Arduino, se non è presente un nuovo messaggio reitera quello precedente.\\
Successivamente il thread resta in attesa di un messaggio da Arduino e, se quest'ultimo è diverso 
dal precedente, allora lo passa a IncomingMessage che lo decodificherà
e notificherà i propri Observer della presenza di un nuovo messaggio, altrimenti lo ignora.\\
Il messaggio da inviare è memorizzato nel campo privato mOutgoing che viene di volta 
in volta impostato da RobotLogic tramite il ``setter''\footnote{Metodo che fornisce 
l'accesso in scrittura ad un campo privato di un oggetto.} \emph{setOutgoing()}.
L'uso degli ``short-lived thread'' in Java è piuttosto semplice:
\begin{lstlisting}[caption=Metodo di inizializzazione degli short-lived thread in Communicator] 
private ScheduledExecutorService mScheduler;
...
public void start() {
    CommunicationThread thread = new CommunicationThread();
    mScheduler = Executors.newSingleThreadScheduledExecutor();
    mScheduler.scheduleAtFixedRate(thread, 0, READING_POLLING_TIME, TimeUnit.MILLISECONDS);
}
\end{lstlisting}
Ottenuto da Java il riferimento allo ScheduledExecutorService si imposta l'esecuzione ad 
intervalli regolari di READING\_POLLING\_TIME millisecondi del nostro CommunicatorThread.\\ 
La \emph{read()} fornita dall'ADK è bloccante, quindi finché Arduino
non invia un messaggio, e questo è disponibile sul buffer di lettura, l'esecuzione di 
\emph{run()} resta appesa. Questo comportamento potrebbe portare 
all'indesiderata situazione in cui un messaggio in attesa di essere inviato ad Arduino
venga sovrascritto dal successivo messaggio elaborato da RobotLogic. Per evitare questo scenario
Arduino invia ad ogni iterazione del proprio ciclo \emph{loop()} almeno un messaggio ad
Android, che, in assenza di situazioni particolari, sarà la lettura proveniente dal 
sensore di distanza; in questo modo oltre ad evitare il blocco del thread,
si invia ad Arduino un'informazione comunque utile per la navigazione.


\subsection {Il pacchetto \textit{logic}}
Si occupa di reperire le informazioni dal mondo reale e analizzarle al fine di
eseguire l'azione più adatta.
Contiene tre classi: RobotActivity, RobotLogic e UpdateDirections.

\subsubsection{La classe \emph{RobotActivity}}
Come suggerisce il nome è l'Activity vera e propria, cioè quella classe che il 
sistema operativo istanzia all'avvio dell'app. Essa stessa istanzia e prepara tutti gli 
altri oggetti per l'esecuzione. Implementa due interfacce: View.OnTouchListener 
e CvCameraViewListener. 
La prima permette di gestire gli input da touch screen,
la seconda è un'interfaccia presente nella libreria OpenCV e permette di ``intercettare''
i frame provenienti dalla camera, prima che vengano renderizzati a schermo, tramite 
l'override\footnote{Tecnica che permette di ridefinire il comportamento di un metodo 
ereditato.} del metodo \textit{OnCameraFrame()}.

All'avvio si occupa di inizializzare OpenCV tramite la 
callback \textit{BaseLoaderCallback} e ottiene il riferimento all'istanza dell'ADK
tramite l'ADKToolkit, inizializza il Communicator e passa il riferimento di quest'ultimo
a TargetSearch durante l'esecuzione.
\\È buona norma interrompere le connessioni e liberare il canale usato 
nel momento in cui un'app viene chiusa. Per questo nel metodo \emph{onDestroy()} 
viene chiuso il canale usato per comunicare con Arduino tramite il metodo \emph{close()}
fornito dall'ADKToolkit e viene fermato lo scheduler che esegue il Communicator\\
In aggiunta alle normali funzioni di un'Activity, RobotActivity integra un 
listener per gli eventi touch localizzati all'interno della porzione di 
interfaccia utente che mostra il video proveniente dalla camera. In tal caso, 
viene invocato il metodo \emph{onTouch()} ereditato da View.OnTouchListener 
che esegue la media dei colori presenti in una regione di 8x8 px intorno alle coordinate
in cui è avvenuto il tocco da parte dell'utente. Il colore calcolato, 
che rappresenta l'oggetto ricercato dall'agente nella scena, sarà passato 
alla classe TargetSearch del pacchetto \textbf{opencv} tramite il metodo pubblico 
di quest'ultima \emph{setTargetHsvColor()}.

\subsubsection{La classe \emph{UpdateDirections}}
Questa classe è un \emph{singleton} e si occupa di mostrare all'utente tramite 
immagini e testi quello che l'agente
sta facendo e quale sarà la sua prossima  mossa. Dovendo agire 
sull'UI\footnote{User Interface, interfaccia utente.} deve essere eseguita sul thread
che si occupa dell'UI, per questo implementa l'interfaccia \emph{Runnable} e 
ogni sua esecuzione è lanciata  tramite \emph{runOnUiThread()}. 
Le informazioni visualizzabili sono limitate e ben distinte,
ad ognuna corrisponde un metodo da invocare per visualizzare quell'informazione
a schermo. I metodi disponibili sono: 
\begin{itemize}
	\item \emph{left()}: indica che l'obiettivo è visibile, è stato individuato e si trova alla sinistra dell'agente.
	\item \emph{right()}: indica che l'obiettivo è visibile, è stato individuato e si trova alla destra dell'agente.
	\item \emph{aimed()}: indica che l'obiettivo è visibile, è stato individuato e si trova esattamente di fronte all'agente che si muoverà in quella direzione.
	\item \emph{search()}: indica che l'obiettivo non è visibile, l'agente si muoverà secondo l'algoritmo di ricerca.
	\item \emph{found()}: indica che l'obiettivo è visibile e l'agente si trova a meno di 30 centrimetri.
	\item \emph{avoidingLeft()}: indica che è presente un ostacolo sul percorso dell'agente a meno di 30 centimetri. L'agente lo aggirerà verso sinistra. 
	\item \emph{avoidingRight()}: indica che è presente un ostacolo sul percorso dell'agente a meno di 30 centimetri. L'agente lo aggirerà verso destra.
	\item \emph{chooseColor()}: indica che l'agente è in attesa che venga impostato il colore da cercare. 
\end{itemize}
La classe espone anche altri metodi che mostrano (\emph{show()}) o nascondono 
(\emph{hide()}) la porzione di interfaccia che visualizza le indicazioni, oppure bloccano (\emph{lock()})
e sbloccano (\emph{unlock()}) la possibilità di cambiare le indicazioni visualizzate.

\subsubsection{La classe astratta \emph{BaseAi} e l'interfaccia \emph{IBaseAi} del pacchetto \emph{ai}}
Forniscono la base di partenza per la classe RobotLogic.\\
L'interfaccia ha due metodi: \emph{targetPosition()} e \emph{think()}.
BaseAi sfrutta l'interfaccia IBaseAi e implementa il metodo \emph{targetPosition()}. 
Tramite questo metodo, TargetSearch fornisce all'IA la larghezza del frame, la posizione 
dell'obiettivo e il \emph{buonding rect} dell'obiettivo; a partire da quest'ultimi saranno 
calcolati i valori di \emph{mFrameWidth}, \emph{mTargetCenter}, \emph{mTargetInSight},
\emph{mTargetDirection} e \emph{mTargetWidth} che saranno utilizzati in \emph{think()}.\\
Con questa organizzazione si fa si che i comportamenti e i dati indispensabili per una classe di 
IA siano definiti in BaseAi e quindi ogni nuova classe nata per sostituire o migliorare
la logica attuale dovrà estendere BaseAi e implementare \emph{think()} 

\subsubsection{La classe \emph{RobotLogic}}
La classe RobotLogic racchiude l'algoritmo che governa il robot.\\
Viene chiamata in causa ogni volta che arriva un nuovo messaggio da Arduino. 
Per far questo si è usato il design pattern ``Observer-Observable'' 
in cui l'``Observer'' è questa stessa classe e l'``Observable''
è la classe IncomingMessage del pacchetto \textbf{messaging}.\\
Alla ricezione di ogni messaggio viene invocato il metodo \emph{getIncoming()} 
della classe IncomingMessage che fornisce un'istanza di ArduinoMessage che contiene 
la decodifica del messaggio appena ricevuto. Se il messaggio
contiene informazioni sulla distanza del primo oggetto nella direzione dell'agente
allora tale distanza viene salvata nell'istanza in modo che successivamente si
possa usare per valutare in modo più preciso lo stato dell'ambiente.\\
Il metodo principale della classe è \emph{think()} ed è invocato ogni volta che
dal pacchetto \textbf{opencv}, e in particolare dalla classe TargetSearch, giunge un aggiornamento
sull'obiettivo, la sua eventuale presenza in scena e la sua posizione. Viene 
effettivamente eseguito \emph{think()} solo se è stato premuto il pulsante \emph{Start}
presente sull'interfaccia utente; questo metodo come prima cosa, stabilisce in che fase l'iterazione precedente ha portato il sistema. \\
Le possibilità sono:
\begin{itemize}
	\item ``Cheer Phase'': indica che l'obiettivo è stato trovato e l'agente sta
	girando su se stesso per segnalare la fine della ricerca.
	\item ``Avoiding Phase'': indica che sulla traiettoria dell'agente si è presentato un ostacolo e lo sta aggirando. Si compone di tre sottofasi:
	\begin{itemize}
		\item Fase 1: scegliere in modo casuale una direzione tra destra e sinistra e ruota di circa 90° in quella direzione. 
		\item Fase 2: si muove in avanti per un tempo prestabilito.
		\item Fase 3: ruota di 90° nella direzione opposta a quella scelta nella fase 1.
	\end{itemize}
	\item ``Search Phase'': indica che l'obiettivo non è stato ancora trovato e l'agente si sta muovendo per trovarlo.
	\end{itemize}
Se si trova nella ``Cheer Phase'' ignora ogni comunicazione proveniente da 
Arduino, finisce la rotazione di segnalazione e invoca il metodo \emph{reset()} di 
RobotActivity per preparare il sistema all'inserimento di un nuovo obiettivo da 
parte dell'utente.\\
Se si trova nella ``Avoiding Phase'' esegue in successione le tre fasi. 
Si può interrompere solo se durante le manovre di aggiramento dell'ostacolo
l'obiettivo compare nella scena.\\
Se si trova nella ``Search Phase'' controlla se l'obiettivo è presente in scena e 
si trova a meno di 30 centimetri, in caso di risposta affermativa ferma l'agente,
interrompe l'esecuzione di \emph{think()} e attiva la ``Cheer Phase''. 
Se l'obiettivo non è in vista ma c'è un oggetto a meno di 30 centimetri ferma l'agente
e attiva la ``Avoiding Phase''.\\
Se l'obiettivo non è visibile rimane in ``Search Phase'' e si muove in avanti.\\
Se l'obiettivo è visibile ma si trova a più di 30 centimetri effettua le correzioni di rotta
necessarie per portarlo in direzione di marcia.\\
Se l'obiettivo è precisamente di fronte all'agente si muoverà in quella direzione.\\ 
La rotazione necessaria per portare l'obiettivo esattamente di fronte all'agente 
implica movimenti lenti e precisi che è difficile ottenere con i motori DC di cui è
fornito l'agente. Lo scenario tipico è che i motori, impostati ad una certa potenza, 
si sforzano per ruotare l'agente senza riuscirci. Aumentare la potenza, anche di un piccolo 
quantitativo, fa ruotare l'agente velocemente. Purtroppo l'energia richiesta per 
mettere in rotazione l'agente cambia in funzione di troppe variabili: 
la direzione di rotazione, l'uso di entrambi i cingoli o solamente uno, 
la presenza di piccoli ostacoli sotto l'agente. Per ovviare a questo problema che impedisce 
una corretta movimentazione dell'agente quando sono necessari movimenti precisi 
si è usata una soluzione adattiva che permette all'agente di trovare sempre la 
minima energia necessaria per muoversi. Per far questo l'agente prende come riferimento 
la posizione dell'obiettivo e tenta di ruotare, se all'iterazione successiva 
non nota uno spostamento relativamente all'obiettivo, allora aumenta 
l'energia inviata ai motori. L'incremento di energia viene arrestato non appena 
l'agente riesce a muoversi; questo produce una rotazione fluida e controllata.

\section {Arduino} 
La prima operazione effettuata su Arduino è l'inizializzazione dell'ADK fornendo 
version, model e manufacturer identici a quelli indicati in usb\_accessory\_filter.xml 
nell'app Android.

Nel \emph{setup()} avviene la configurazione dei pin utilizzati come input o output e si inizializza
la connessione seriale a 115200 bps.\\
In Arduino il metodo principale è \emph{loop()}, che come dice il nome stesso viene eseguito
in ciclo infinito. Gli stati assegnati agli output sono persistenti attraverso 
le varie iterazioni del ciclo.
La prima operazione fatta è il controllo dei sensori di riflessività. Se dovessero 
essere in stato di ``warning'' si interrompe l'esecuzione del \emph{loop()} 
forzandolo a passare all'iterazione successiva e si fa un altro controllo; se i 
sensori sono ancora in ``warning'' allora si innesca la modalità ``emergency''.
Durante questa fase la sicurezza dell'agente è prioritaria: vengono ignorati tutti 
i messaggi proveniente da Android fino alla risoluzione della situazione di emergenza.\\
Le situazioni di emergenza sono gestite dal metodo \emph{emergency()} e possono 
essere di tre tipi:
\begin{itemize}
	\item Allarme sul sensore sinistro: esegue una breve retromarcia 
	e ruota lentamente sul posto verso destra.
	\item Allarme sul sensore destro: esegue una breve retromarcia 
	e ruota lentamente sul posto verso sinistra.
	\item Allarme su entrambi i sensori: esegue una breve retromarcia 
	e ruota velocemente sul posto verso sinistra.
\end{itemize}
Il resto del metodo \emph{loop()} è interamente compreso dentro un
\emph{if} che controlla se Arduino è collegato ad una periferica in grado di 
comunicare secondo il protocollo Android Open Accessory (AOA).\\
Successivamente Arduino controlla se è disponibile un messaggio inviato da Android, 
procedendo in tal caso alla decodifica ed all'esecuzione del comando ricevuto. 
In caso contrario entra in uno stato ``conservativo'' in cui è connesso ad una periferica 
ma non sta ricevendo comandi. L'accesso a questo stato provoca l'immediata fermata 
dell'agente in quanto, dato che i motori continuerebbero ad eseguire l'ultimo 
comando inviato, si muoverebbe senza controllo esponendosi a dei pericoli.\\
La decodifica del comando è effettuata da \emph{decodeCommand()} che divide la stringa 
nelle sue tre parti fondamentali command, param1, param2. Controlla che command
sia un comando conosciuto e, nel caso che il comando preveda dei parametri aggiuntivi,
che param1 e param2 rientrino negli intervalli previsti. In seguito tramite un costrutto 
\emph{switch} applicato a command esegue le azione previste per quel dato comando o comando-parametri
ricevuti. Per rafforzare l'approccio conservativo sopra citato, se il comando 
ricevuto non riesce ad essere decodificato correttamente 
si fermano i motori finché non arriva un comando legittimo.\\
Alla fine del ciclo \emph{loop()}, che sia stato ricevuto un messaggio corretto o meno,
viene attivato il sensore di distanza a ultrasuoni, calcolata la distanza in centimetri
con la formula illustrata precedentemente nella sezione 2.3.2 e inviata ad Android
come messaggio di tipo INFO.\\
Il modulo Arduino include, inoltre, le seguenti funzioni con le rispettive responsabilità:
\begin{itemize}
\item \emph{setDirection()}: i motori sono collegati rispettando la stessa 
polarità: dando la stessa potenza ad entrambi ruoteranno nello stesso verso. 
Questo, considerando che sono montati in modo speculare sui due cingoli,
comporterà una rotazione sul posto per l'agente. Per ovviare 
il problema questo metodo riceve due ha come parametri \emph{side} e \emph{direction}: 
\emph{side} identifica su quale cingolo si vuole impostare la direzione il cui valore 
può essere LEFT, RIGHT, BOTH mentre \emph{direction} indica la direzione che si 
vuole impostare e può assumere i valori FORWARD e BACKWARD.
Con queste informazioni sarà il metodo ad impostare le direzioni corrette ai motori 
per far si che l'agente vada nella direzione effettivamente desiderata.
\item \emph{brake()} e \emph{releaseBrake()}: rispettivamente attivano e disattivano i 
freni dei motori. L'Arduino Motor Shield modula il segnale inviato ai motori in 
modo da farli fermare velocemente.
\item \emph{moveForward()} e \emph{moveBackward()}: impostano la direzione di marcia 
desiderata con \emph{setDirection()} e attivano i motori alle potenze ricevute come 
parametri.
\item \emph{turnLeft()} e \emph{turnRight()}: attivano il cingolo opposto alla 
direzione di rotazione richiesta alla potenza ricevuta per parametro. Se il  parametro
mode è impostato su TURN\_ON\_SPOT significa che è stata richiesta da Android la 
rotazione sul posto e quindi oltre al cingolo sopracitato attiva anche l'altro 
con pari potenza ma direzione opposta.
\item \emph{stop()}: disattiva i motori. Può effettuare una fermata HARD o una SOFT.
Nel primo caso usa \emph{brake()} per diminuire il tempo di frenata mentre nel 
secondo il robot sarà arrestato dall'attrito con la superficie.
\item i metodi \emph{emergency()}, \emph{sensorsOk()}, \emph{FRIsOut()} e \emph{FLIsOut()}
lavorano tutti all'unisono per evitare che l'agente esca dall'area di test: leggono costantemente 
i valori di riflessività rilevati dai sensori QRD1114 e agiscono di conseguenza come 
illustrato all'inizio della presente sezione. 
\end{itemize}